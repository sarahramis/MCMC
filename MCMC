import numpyro
import numpyro.distributions as dist
from jax import random
import numpy as np
import numpyro.infer as infer
import jax.numpy as jnp
import jax


#Setup the MCMC
kernel = infer.NUTS(rescorla_wagner_model)
mcmc = infer.MCMC(kernel, num_warmup=500, num_samples=1000)


def update_rescorla_wagner(carry, input):
    v, alpha, beta = carry
    stimulus, reward = input
    prediction = beta * v * stimulus
    prediction_error = reward - prediction
    new_v = v + alpha * prediction_error * stimulus
    return (new_v, alpha, beta), prediction


def rescorla_wagner_model(stimuli, rewards):
    alpha = numpyro.sample("alpha", dist.Uniform(0, 1))  # Learning rate
    beta = numpyro.sample("beta", dist.Uniform(0, 5))  # Influence of prediction error
    v_initial = 0.0  # Initial value estimate

    # Prepare inputs for scan
    inputs = (stimuli, rewards)

    # Initial carry state (v, alpha, beta)
    initial_carry = (v_initial, alpha, beta)

    # Using scan to process the time series
    _, predictions = jax.lax.scan(update_rescorla_wagner, initial_carry, inputs, length=len(stimuli))

    # Sampling the observed data using predictions from scan
    numpyro.sample("obs", dist.Normal(predictions, 1.0), obs=rewards)

def update_simulation(carry, input):
    v, true_alpha, true_beta = carry
    stimulus = input
    prediction = true_beta * v * stimulus
    reward = prediction + jax.random.normal(jax.random.PRNGKey(np.random.randint(0, 10000)), shape=())  # Noise
    new_v = v + true_alpha * (reward - prediction) * stimulus
    return (new_v, true_alpha, true_beta), (stimulus, reward)

def simulate_rescorla_wagner_data(num_trials, true_alpha, true_beta):
    stimuli = np.random.randint(0, 2, size=num_trials)  # Binary stimuli (0 or 1)
    initial_v = 0.0  # Initial belief

    # Initial carry (state) and dummy input for scan
    initial_carry = (initial_v, true_alpha, true_beta)
    inputs = stimuli

    # Using scan to simulate the data
    final_state, outputs = jax.lax.scan(update_simulation, initial_carry, inputs)

    # Unpacking outputs
    stimuli, rewards = outputs
    return stimuli, rewards

# Example of how to run this model with NumPyro's MCMC
def run_inference(stimuli, rewards):
    from numpyro.infer import MCMC, NUTS
    import numpy as np

    # Convert data to device array if not already (JAX works best with its own arrays)
    stimuli = jnp.array(stimuli)
    rewards = jnp.array(rewards)

    # Setting up the MCMC
    kernel = NUTS(rescorla_wagner_model)
    mcmc = MCMC(kernel, num_warmup=500, num_samples=1000)

    # Running the MCMC
    mcmc.run(jax.random.PRNGKey(0), stimuli=stimuli, rewards=rewards)
    mcmc.print_summary()
    return mcmc.get_samples()

# Dummy data for demonstration
stimuli = jnp.array([1, 0, 1, 1])  # Example sequence of stimuli
rewards = jnp.array([1, 0, 0, 1])  # Corresponding sequence of rewards


def simulate_rescorla_wagner_data(key, num_trials, true_alpha, true_beta):
    stimuli = jax.random.choice(key, 2, shape=(num_trials,), p=jnp.array([0.5, 0.5]))
    rewards = jnp.zeros(num_trials)
    v = 0.0

    def update(carry, input):
        v = carry
        stimulus = input
        prediction = true_beta * v * stimulus
        reward = prediction + jax.random.normal(jax.random.split(key)[0], shape=())
        new_v = v + true_alpha * (reward - prediction) * stimulus
        return new_v, reward

    v, rewards = jax.lax.scan(update, v, stimuli)
    return stimuli, rewards

# Using the data with run_inference
key = jax.random.PRNGKey(0)
num_trials = 50
true_alpha = 0.1
true_beta = 2.0
stimuli, rewards = simulate_rescorla_wagner_data(key, num_trials, true_alpha, true_beta)
samples = run_inference(stimuli, rewards)


samples = run_inference(stimuli, rewards)

mcmc.run(jax.random.PRNGKey(0), stimuli=stimuli, rewards=rewards)

if mcmc.get_samples() is None:
    print("No samples were collected")
else:
    print("Samples are available")

samples = mcmc.get_samples()
if samples:
    idata = az.from_dict(posterior={k: v[None, :] for k, v in samples.items()})
else:
    print("Failed to retrieve samples for conversion.")

import matplotlib.pyplot as plt
import arviz as az

# Convert samples to an InferenceData object for easy handling
idata = az.from_numpyro(mcmc)

print("Summary of posterior distributions:")
summary = az.summary(idata, var_names=["alpha", "beta"])
print(summary)



# Example RMSE calculation
alpha_rmse = np.sqrt(np.mean((samples['alpha'] - true_alpha) ** 2))
beta_rmse = np.sqrt(np.mean((samples['beta'] - true_beta) ** 2))
print(f"RMSE for alpha: {alpha_rmse}, RMSE for beta: {beta_rmse}")

az.plot_posterior(idata, var_names=["alpha", "beta"])
plt.show()
